{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffq6A2-ifzAA"
      },
      "source": [
        "# ДЗ1. Классификация текстов и тематическое моделирование"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом домашнем задании вам предстоит построить классификатор текстов и проанализировать их содержание. Мы будем предсказывать эмоциональную окраску (позитив/негатив) твиттов о коронавирусе, а также выделять основные темы обсуждения.\n",
        "\n",
        "В ходе работы вы пройдете весь NLP-пайплайн:\n",
        "\n",
        "1.  **Предобработка.** Токенизация, очистка от шума, стемминг и лемматизация.\n",
        "2.  **Векторизация.** Построение признаков методами Bag-of-Words и TF-IDF.\n",
        "3.  **Классификация.** Обучение логистической регрессии и анализ важности признаков.\n",
        "4.  **Тематическое моделирование.** Выделение скрытых тем в твиттах с помощью LDA.\n",
        "5.  **Эмбеддинги.** Использование плотных векторных представлений (Word2Vec) для классификации.\n",
        "\n",
        "Вот несколько правил, который помогут нам сделать работу приятнее и продуктивнее:\n",
        "\n",
        "* Домашнее задание оценивается в 11 баллов.\n",
        "* Если в задании есть вопрос на рассуждение, то за отсутствие ответа на него балл за задание будет снижен вполовину.\n",
        "* Можно использовать любые свободные источники с *обязательным* указанием ссылки на них. Если в работе вы используете генеративные модели, их указание обязательно.\n",
        "* Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
        "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе."
      ],
      "metadata": {
        "id": "jFECC3uCOVnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting"
      ],
      "metadata": {
        "id": "SXAYEdpbPX0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNGRVO7_g9mz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import  List\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  -O 'tweets.csv' -q 'https://www.dropbox.com/scl/fi/9aa3ayx7ax3uy1r04lgsn/tweets.csv?rlkey=svfde8wc04ayvqnkwhwb6jm04&st=wgvibiqc&dl=0'"
      ],
      "metadata": {
        "id": "vUcvF9wmAPYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOy8iHJQg_Ss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "9241d416-978f-4d01-b62d-d1c45b7189f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       UserName  ScreenName           Location     TweetAt  \\\n",
              "8887      14596       59548                NaN  20-03-2020   \n",
              "24382     33616       78568                NYC  06-04-2020   \n",
              "13777     20520       65472  Hamilton, Ontario  22-03-2020   \n",
              "810        4771       49723               ????  17-03-2020   \n",
              "\n",
              "                                           OriginalTweet           Sentiment  \n",
              "8887   ItÃÂs eerie in the grocery store toilet pape...            Negative  \n",
              "24382  We welcome the responses of Amazon Facebook Go...            Negative  \n",
              "13777  People are becoming desperate in these toiletp...            Negative  \n",
              "810    I haven't tweeted at all about #COVID2019 beca...  Extremely Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6c96d36-d743-499c-bf52-811f800b80ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8887</th>\n",
              "      <td>14596</td>\n",
              "      <td>59548</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20-03-2020</td>\n",
              "      <td>ItÃÂs eerie in the grocery store toilet pape...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24382</th>\n",
              "      <td>33616</td>\n",
              "      <td>78568</td>\n",
              "      <td>NYC</td>\n",
              "      <td>06-04-2020</td>\n",
              "      <td>We welcome the responses of Amazon Facebook Go...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13777</th>\n",
              "      <td>20520</td>\n",
              "      <td>65472</td>\n",
              "      <td>Hamilton, Ontario</td>\n",
              "      <td>22-03-2020</td>\n",
              "      <td>People are becoming desperate in these toiletp...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>4771</td>\n",
              "      <td>49723</td>\n",
              "      <td>????</td>\n",
              "      <td>17-03-2020</td>\n",
              "      <td>I haven't tweeted at all about #COVID2019 beca...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6c96d36-d743-499c-bf52-811f800b80ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6c96d36-d743-499c-bf52-811f800b80ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6c96d36-d743-499c-bf52-811f800b80ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-14249368-517d-4f0c-b70b-9d62613f80cd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14249368-517d-4f0c-b70b-9d62613f80cd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-14249368-517d-4f0c-b70b-9d62613f80cd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('/content/tweets.csv', encoding='latin-1')\n",
        "df.sample(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2OiDog9ZBlS"
      },
      "source": [
        "Для каждого твитта указано:\n",
        "\n",
        "\n",
        "*   UserName - имя пользователя, заменено на целое число для анонимности\n",
        "*   ScreenName - отображающееся имя пользователя, заменено на целое число для анонимности\n",
        "*   Location - местоположение\n",
        "*   TweetAt - дата создания твитта\n",
        "*   OriginalTweet - текст твитта\n",
        "*   Sentiment - эмоциональная окраска твитта (целевая переменная)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZTMseDkhTC7"
      },
      "source": [
        "## Задание 1 Подготовка (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx2-odn9hdAW"
      },
      "source": [
        "Целевая переменная находится в колонке `Sentiment`.  Преобразуйте ее таким образом, чтобы она стала бинарной: 1 - если у твитта положительная или очень положительная эмоциональная окраска и 0 - если отрицательная или очень отрицательная."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaQKQ1zEjP15"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ┌(ಠ_ಠ)┘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGq1FxJ-kBo5"
      },
      "source": [
        "Сбалансированы ли классы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7gdNtxckK5V"
      },
      "outputs": [],
      "source": [
        "# your code here (づ｡◕‿‿◕｡)づ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng8BCelMkWb0"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmSIBSsLk5Zz"
      },
      "source": [
        "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их строкой 'Unknown'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhUVRkR5kxa7"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# (⌐■_■)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tzt27tfjUpq"
      },
      "source": [
        "Разделите данные на обучающие и тестовые в соотношении 7 : 3 и укажите `random_state=0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSLOA9tIj9Z6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = # your code here [✖‿✖]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9RrPUsJlL60"
      },
      "source": [
        "## Задание 2 Токенизация (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dz_b7Xopc_R"
      },
      "source": [
        "Постройте словарь на основе обучающей выборки и посчитайте количество встреч каждого токена с использованием самой простой токенизации - деления текстов по пробельным символам и приведения токенов в нижний регистр."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFr67WOJphny"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ٩(⁎❛ᴗ❛⁎)۶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe0h2Jqkpnao"
      },
      "source": [
        "Какой размер словаря получился?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umyENA7EpokD"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ヾ(๑╹◡╹)ﾉ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d2G1Z-Qpqkd"
      },
      "source": [
        "Выведите 10 самых популярных токенов с количеством встреч каждого из них. Объясните, почему именно эти токены в топе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Impi32a_pssg"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ฅ^•ﻌ•^ฅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtuJCD0ApuFd"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7DTQDkWsVYp"
      },
      "source": [
        "Удалите стоп-слова из словаря и выведите новый топ-10 токенов (и количество встреч) по популярности.  Что можно сказать  о нем?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8csSAdgTsnFx"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# your code here ʕ•ᴥ•ʔ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZH0x2Lzs-Dh"
      },
      "source": [
        "**Ответ:**  # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKSGRyI-uor0"
      },
      "source": [
        "Также выведите 20 самых непопулярных слов (если самых непопулярных слов больше, выведите любые 20 из них) Почему эти токены непопулярны, требуется ли как-то дополнительно работать с ними?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moArbwfvun9t"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# (っ˘ڡ˘ς)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRp3J1gQunlR"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx9LQOSPzvjV"
      },
      "source": [
        "Теперь воспользуемся токенайзером получше - TweetTokenizer из библиотеки nltk. Примените его и посмотрите на топ-10 популярных слов. Чем он отличается от топа, который получался раньше? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G1UkyVxzvFY"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# your code here\n",
        "# ¯\\_(ツ)_/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50eVUnJN1Zxl"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gqQgiMs11bs"
      },
      "source": [
        "Удалите из словаря стоп-слова и пунктуацию, посмотрите на новый топ-10 слов с количеством встреч, есть ли теперь в нем что-то не похожее на слова?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yHWdFrp0Mup"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "# your code here\n",
        "# ٩(ˊ〇ˋ*)و"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZJqXELP_Yxy"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzXjMsSB_kXB"
      },
      "source": [
        "Скорее всего в некоторых топах были неотображаемые символы или отдельные буквы не латинского алфавита. Уберем их: удалите из словаря токены из одного символа, позиция которого в таблице Unicode 128 и более (`ord(x) >= 128`)\n",
        "\n",
        "Выведите топ-10 самых популярных и топ-20 непопулярных слов. Чем полученные топы отличаются от итоговых топов, полученных при использовании токенизации по пробелам? Что теперь лучше, а что хуже?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1695hlkS_1-J"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# =^･ｪ･^="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzjHAKIlDvc6"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcDf9_6HB2zm"
      },
      "source": [
        "Выведите топ-10 популярных хештегов (токены, первые символы которых - #) с количеством встреч. Что можно сказать о них?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk4fygCUBw3l"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# (⊙_⊙)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6NeNWBkDxM7"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLYBg7caD5GA"
      },
      "source": [
        "То же самое проделайте для ссылок на сайт https://t.co Сравнима ли популярность ссылок с популярностью хештегов? Будет ли информация о ссылке на конкретную страницу полезна?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXbm1oeaCK9S"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# (❍ᴥ❍ʋ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at6lRYZ8A07N"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOGdUU1kBU1D"
      },
      "source": [
        "Используем опыт предыдущих экспериментов и напишем собственный токенайзер, улучшив TweetTokenizer. Функция tokenize должна:\n",
        "\n",
        "\n",
        "\n",
        "*   Привести текст в нижний регистр\n",
        "*   Применить TweetTokenizer для  выделения токенов\n",
        "*   Удалить стоп-слова, пунктуацию, токены из одного символа с позицией в таблице Unicode 128 и более,  ссылки на t.co\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctEsB6xkFrrK"
      },
      "outputs": [],
      "source": [
        "def custom_tokenizer(text):\n",
        "\n",
        "  # your code here (＠_＠)\n",
        "\n",
        "  return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwbgtYkJGYym",
        "outputId": "5808765b-3448-45e6-ccc1-7cd65f6371ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample', 'text', '@sample_text', '#sampletext']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "custom_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wURVABmXHk97"
      },
      "source": [
        "## Задание 3 Векторизация текстов (1 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H44iXkoHIQfN"
      },
      "source": [
        "Обучите CountVectorizer с использованием custom_tokenizer в качестве токенайзера. Как размер полученного словаря соотносится с размером изначального словаря из начала задания 2?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer # your code here (￢_￢)\n",
        "\n",
        "print(len(cv.vocabulary_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHn_limQl3BI",
        "outputId": "8e9c1826-319f-4376-f06e-c30c2eb82648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsfmaSGoItUm"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm6UHNmqKZT0"
      },
      "source": [
        "Посмотрим на какой-нибудь конкретный твитт:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJVjjfqOJh8m"
      },
      "outputs": [],
      "source": [
        "ind = 9023\n",
        "train.iloc[ind]['OriginalTweet'], train.iloc[ind]['Sentiment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBMIHBI5KdaS"
      },
      "source": [
        "Автор твитта не доволен ситуацией с едой во Франции и текст имеет резко негативную окраску.\n",
        "\n",
        "Примените обученный CountVectorizer для векторизации данного текста, и попытайтесь определить самый важный токен и самый неважный токен (токен, компонента которого в векторе максимальна/минимальна, без учета 0). Хорошо ли они определились, почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NcAllaEKsJj"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ♡ (´｡• ω •｡`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpEsl1k_NF4T"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4DsEQpLO3J6"
      },
      "source": [
        "Теперь примените TfidfVectorizer и  определите самый важный/неважный токены. Хорошо ли определились, почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSNzdK3ENGB3"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ヽ(♡‿♡)ノ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYao_UhqQADm"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGRJPqfWSesQ"
      },
      "source": [
        "Найдите какой-нибудь положительно окрашенный твитт, где TfidfVectorizer хорошо (полезно для определения окраски) выделяет важный токен, поясните пример.\n",
        "\n",
        "*Подсказка:* явно положительные твитты можно искать при помощи положительных слов (good, great, amazing и т. д.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRbQ2CHiSuJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c4b34a7d-1076-4e1e-ad5c-9466fd2097c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [UserName, ScreenName, Location, TweetAt, OriginalTweet, Sentiment]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train[train['OriginalTweet'].apply(lambda x: 'your_good_word_here' in x) & (train['Sentiment'] == 1)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# (ﾉ◕ヮ◕)ﾉ*:･ﾟ✧"
      ],
      "metadata": {
        "id": "jSjbKPCWk87K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTv9ST2_U6NA"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVEuZm8BHms6"
      },
      "source": [
        "## Задание 4 Обучение первых моделей (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JADkO3sfXdOG"
      },
      "source": [
        "Примените оба векторайзера для получения матриц с признаками текстов.  Выделите целевую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DguoiXhCX2oN"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# (✿◠‿◠)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FX1KSOfYSx4"
      },
      "source": [
        "Обучите логистическую регрессию на векторах из обоих векторайзеров. Посчитайте долю правильных ответов на обучающих и тестовых данных. Какой векторайзер показал лучший результат? Что можно сказать о моделях?\n",
        "\n",
        "Используйте `sparse` матрицы (после векторизации), не превращайте их в `numpy.ndarray` или `pd.DataFrame` - может не хватить памяти."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tb3eh8UXJ6v"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# your code here ᕙ(⇀‸↼‶)ᕗ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_wO7rCmv7K"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSOR1i3mjrys"
      },
      "source": [
        "## Задание 5 Стемминг (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6ONBWNPjuq-"
      },
      "source": [
        "Для уменьшения словаря можно использовать стемминг.\n",
        "\n",
        "Модифицируйте написанный токенайзер, добавив в него стемминг с использованием SnowballStemmer. Обучите Count- и Tfidf- векторайзеры. Как изменился размер словаря?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVfA2-iMkQBb"
      },
      "outputs": [],
      "source": [
        "def custom_stem_tokenizer(text):\n",
        "  # your code here (－‸ლ)\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QmrjYtqnlPd",
        "outputId": "cd91291d-9676-4611-9fc4-28afaed58963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sampl', 'text', '@sample_text', '#sampletext', 'ad', 'word', 'check', 'stem']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "custom_stem_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext adding more words to check stemming')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAvUTmaplzOS",
        "outputId": "566207fe-183b-4ed6-d333-f86f0cc9ae38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36652\n"
          ]
        }
      ],
      "source": [
        "cv = CountVectorizer # your code here ( ͡° ͜ʖ ͡°)\n",
        "\n",
        "print(len(cv.vocabulary_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyzs5TaAoHP6"
      },
      "source": [
        "**Ответ** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OkncHI8oRmd"
      },
      "source": [
        "Обучите логистическую регрессию с использованием обоих векторайзеров. Изменилось ли качество? Есть ли смысл применять стемминг?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykZJPphEoZ5W"
      },
      "outputs": [],
      "source": [
        "# your code here ( • ε •)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCRlrODro0h8"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYWGQNEDqLC-"
      },
      "source": [
        "## Задание  6 Работа с частотами (1.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hq-tl5mqUSn"
      },
      "source": [
        "Еще один способ уменьшить количество признаков - это использовать параметры min_df и max_df при построении векторайзера  эти параметры помогают ограничить требуемую частоту встречаемости токена в документах.\n",
        "\n",
        "По умолчанию берутся все токены, которые встретились хотя бы один раз.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1SiD4DE3WZ2"
      },
      "source": [
        "Подберите max_df такой, что размер словаря будет 36651 (на 1 меньше, чем было). Почему параметр получился такой большой/маленький?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
        "                        max_df= # (づ￣ ³￣)づ\n",
        "                        ).fit(\n",
        "                            # (＃￣0￣)\n",
        "                            )\n",
        "print(len(cv_df.vocabulary_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3YLb8PViExb",
        "outputId": "b6d67654-d232-4e11-a5ca-6f2145053e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here ( •_•)>⌐■-■"
      ],
      "metadata": {
        "id": "tyEpkJUkjnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdZYoGZR4UsA"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gRIUaB1u32f"
      },
      "source": [
        "Подберите min_df (используйте дефолтное значение max_df) в CountVectorizer таким образом, чтобы размер словаря был 3700 токенов (при использовании токенайзера со стеммингом), а качество осталось таким же, как и было. Что можно сказать о результатах?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSnMJkn9XmsT",
        "outputId": "e0d8eb21-e5d7-46b4-e1d1-4b1ae220e9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3700\n"
          ]
        }
      ],
      "source": [
        "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
        "                        min_df= # ( > ﹏ < )\n",
        "                        ).fit(\n",
        "                            # (T_T)\n",
        "                            )\n",
        "print(len(cv_df.vocabulary_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here (☞ﾟヮﾟ)☞"
      ],
      "metadata": {
        "id": "mvMDwpdfjm8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fGYpUIZx0fk"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В предыдущих заданиях признаки не скалировались. Отскалируйте данные (при словаре размера 3.7 тысяч, векторизованные CountVectorizer), обучите логистическую регрессию, посмотрите качество и выведите `barplot`, содержащий по 10 токенов, с наибольшим по модулю положительными/отрицательными весами. Что можно сказать об этих токенах?"
      ],
      "metadata": {
        "id": "Gx_h_-inKbBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# your code here (✯◡✯)"
      ],
      "metadata": {
        "id": "KBATXJX6LG9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "ThcEfzY1LHET"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktJVOdrIHq7B"
      },
      "source": [
        "## Задание 7 Другие признаки (1.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt3jRCZ2H0Og"
      },
      "source": [
        "Мы были сконцентрированы на работе с текстами твиттов и не использовали другие признаки - имена пользователя, дату и местоположение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52wjewCCo_di"
      },
      "source": [
        "Изучите признаки UserName и ScreenName. Полезны ли они? Если полезны, то закодируйте их, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63thouYZptj6"
      },
      "outputs": [],
      "source": [
        "# your code here ┐(︶▽︶)┌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8_qR-gnpT3a"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ythEcFSkt7y3"
      },
      "source": [
        "Изучите признак TweetAt в обучающей выборке: преобразуйте его к типу datetime и нарисуйте его гистограмму с разделением по цвету на основе целевой переменной. Полезен ли он? Если полезен, то закодируйте его, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here (ノ°益°)ノ"
      ],
      "metadata": {
        "id": "Lxb_k0JLirNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IdLBdpQxM-G"
      },
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поработайте с признаком Location в обучающей выборке. Сколько уникальных значений?"
      ],
      "metadata": {
        "id": "r2JtRPhNP6qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# (╯°□°）╯︵ ┻━┻"
      ],
      "metadata": {
        "id": "xYQZQ1FRNpoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Постройте гистограмму топ-10 по популярности местоположений (исключая Unknown)"
      ],
      "metadata": {
        "id": "6k4JwpRTQISa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here (⋋▂⋌)"
      ],
      "metadata": {
        "id": "J91YkhegJ0mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что многие местоположения включают в себя более точное название места, чем другие (Например, у некоторых стоит London, UK; а у некоторых просто UK или United Kingdom).\n",
        "\n",
        "Создайте новый признак WiderLocation, который содержит самое широкое местоположение (например, из London, UK должно получиться UK). Сколько уникальных категорий теперь? Постройте аналогичную гистограмму."
      ],
      "metadata": {
        "id": "ZOsv3lODTfYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here (´;ω;`)"
      ],
      "metadata": {
        "id": "mSkow6acOMyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Закодируйте признак WiderLocation с помощью OHE таким образом, чтобы создались только столбцы для местоположений, которые встречаются более одного раза. Сколько таких значений?\n"
      ],
      "metadata": {
        "id": "cgyWrD2eVfff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here (ง ͠° ͟ل͜ °)ง"
      ],
      "metadata": {
        "id": "SeJBfBWgPvg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавьте этот признак к матрице отскалированных текстовых признаков, обучите логистическую регрессию, замерьте качество. Как оно изменилось? Оказался ли признак полезным?\n",
        "\n",
        "\n",
        "*Подсказка:* используйте параметр `categories` в энкодере."
      ],
      "metadata": {
        "id": "ZyMX5kZuimPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here ┬─┬ノ( º _ ºノ)"
      ],
      "metadata": {
        "id": "EO1jNPeeim7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "7dHsGlDRYUQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 8 LSA/LSI через SVD: сжатие и качество (1 балл)"
      ],
      "metadata": {
        "id": "BnOo7zZYPf1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF векторы - это очень высокоразмерные и разреженные признаки. Метод LSA (Latent Semantic Analysis) или LSI (Latent Semantic Indexing), которые мы проходили на семинаре, позволяет найти скрытые связи между словами и документами, сжимая матрицу до меньшей размерности $k$. Это делается с помощью SVD-разложения. Иногда это даже улучшает качество классификации, так как убирает шум."
      ],
      "metadata": {
        "id": "8gtJVdtrPrvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим TF-IDF матрицу. Используйте тот же токенайзер, что и в заданиях выше (`custom_tokenizer` или `custom_stem_tokenizer` - на ваш выбор, но зафиксируйте его)."
      ],
      "metadata": {
        "id": "ewI-URr9QCHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Используем тот же токенайзер, что вы выбрали лучшим ранее\n",
        "tokenizer_function = custom_stem_tokenizer # или custom_tokenizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    tokenizer=tokenizer_function,\n",
        "    lowercase=False  # т.к. lower уже делаем в токенайзере\n",
        ")\n",
        "\n",
        "# Обучаем и трансформируем\n",
        "X_train_tfidf = # your code here (ﾉ◕ヮ◕)ﾉ*:･ﾟ✧\n",
        "X_test_tfidf  = # your code here\n",
        "\n",
        "# Выделяем целевую переменную\n",
        "# your code here"
      ],
      "metadata": {
        "id": "WB2hjkOCQErj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь baseline: логистическая регрессия на TF-IDF - замерим качество на полных признаках, чтобы было с чем сравнивать."
      ],
      "metadata": {
        "id": "zE-UdQDeQSOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_tfidf = LogisticRegression(max_iter=2000, random_state=0)\n",
        "\n",
        "# your code here: fit, predict train/test, посчитать accuracy\n",
        "# ( •̀ ω •́ )✧\n"
      ],
      "metadata": {
        "id": "5YkRqzNOQaKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строим LSA и перебираем размерность: посчитайте качество классификации для нескольких значений размерности $k$."
      ],
      "metadata": {
        "id": "8S6znwtnQeqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import pandas as pd\n",
        "\n",
        "k_list = [...]\n",
        "results = []\n",
        "\n",
        "for k in k_list:\n",
        "    print(f\"Training SVD with k={k}...\")\n",
        "\n",
        "    svd = TruncatedSVD(n_components=k, random_state=0)\n",
        "\n",
        "    # Применяем SVD к TF-IDF матрицам\n",
        "    X_train_lsa = # your code here: fit_transform на train (ง •̀_•́)ง\n",
        "    X_test_lsa  = # your code here: transform на test\n",
        "\n",
        "    # Обучаем классификатор на сжатых признаках\n",
        "    clf = # your code here\n",
        "\n",
        "    # your code here: fit, predict, accuracy\n",
        "    # ᕙ(⇀‸↼‶)ᕗ\n",
        "\n",
        "    results.append({\n",
        "        \"k\": k,\n",
        "        \"train_acc\": # ...\n",
        "        \"test_acc\":  # ...\n",
        "    })\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "res_df"
      ],
      "metadata": {
        "id": "RsBEKV4IQyCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визуализируем зависимости? Постройте график зависимости `test accuracy` от `k`."
      ],
      "metadata": {
        "id": "R1yyAfsTQ5rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# your code here\n",
        "# ┐(︶▽︶)┌"
      ],
      "metadata": {
        "id": "nlXlEQI1RCIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Несколько вопросиков**\n",
        "\n",
        "1.  При каком $k$ получилось лучшее тестовое качество?\n",
        "2.  Почему слишком маленькое $k$ может давать низкое качество?\n",
        "3.  Почему слишком большое $k$ (близкое к исходному количеству слов) может не давать выигрыша или даже ухудшать результат?"
      ],
      "metadata": {
        "id": "5F5jGiFzRHON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "2d3CfoMVRUBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 9 Topic Modeling: LDA и интерпретация тем (1 балл)"
      ],
      "metadata": {
        "id": "G2A57jDpRne5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA (Latent Dirichlet Allocation) ищет скрытые темы в корпусе документов. Мы научимся:\n",
        "\n",
        "1.  Обучать LDA по матрице частот (BoW).\n",
        "2.  Интерпретировать темы по топ-словам.\n",
        "3.  (Дополнительно) использовать распределения тем как признаки для классификации."
      ],
      "metadata": {
        "id": "MJ01dyXgRqev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала подготовим CountVectorizer."
      ],
      "metadata": {
        "id": "HgU63f3aRyPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Важно:** для LDA обычно используют `CountVectorizer`, а не `TF-IDF`."
      ],
      "metadata": {
        "id": "Nu0cdlwBRvQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv_lda = CountVectorizer(\n",
        "        # your code here (◕‿◕)\n",
        ")"
      ],
      "metadata": {
        "id": "VoThcvBUR4Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пора обучить LDA. Выберите число тем `n_topics` (например, 10). Обучите модель на `train`. Это может занять некоторое время."
      ],
      "metadata": {
        "id": "W58wFn1YR3xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "n_topics = 10\n",
        "lda = LatentDirichletAllocation(\n",
        "    # your code here: (ﾒ￣▽￣)φ\n",
        ")\n"
      ],
      "metadata": {
        "id": "uYNhmY8QSHgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем топ-слова для каждой темы? Для этого напишите функцию, которая для каждой темы печатает топ-10 слов с наибольшими весами."
      ],
      "metadata": {
        "id": "R4VdyB2PSXJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_top_words(model, feature_names, n_top_words=10):\n",
        "    # model.components_ содержит веса слов для каждой темы\n",
        "    # нужно отсортировать их и вывести соответствующие слова из feature_names\n",
        "\n",
        "    # your code here\n",
        "    # (╭ರ_•́)\n",
        "    pass\n",
        "\n",
        "feature_names = cv_lda.get_feature_names_out()\n",
        "print_top_words(lda, feature_names, n_top_words=10)"
      ],
      "metadata": {
        "id": "byndO_jvSUcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Выберите 3-5 тем, которые получились наиболее понятными, и словами опишите, про что эта тема (например: \"продукты\", \"паника\", \"политика\").\n",
        "2.  Есть ли темы, которые выглядят мусорными (смесь предлогов, общих слов)? Почему так может происходить?"
      ],
      "metadata": {
        "id": "2cT6VY6MSiOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "eCGQCduGSmOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь используем распределение тем в документе как признаки. Получите матрицы тематических распределений для `train` и `test` и обучите логистическую регрессию."
      ],
      "metadata": {
        "id": "UNsSJDgKSv8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lda.transform возвращает вероятность принадлежности документа к каждой из тем\n",
        "X_train_topics = # your code here:\n",
        "X_test_topics  = # your code here\n",
        "\n",
        "clf_topics = LogisticRegression(max_iter=2000, random_state=0)\n",
        "\n",
        "# your code here\n",
        "# ( •̀ ω •́ )✧\n",
        "\n",
        "print(\"LDA-topics train acc:\", # ...)\n",
        "print(\"LDA-topics test acc:\",  # ...)"
      ],
      "metadata": {
        "id": "l3kAMPhbSzPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Как качество классификации на темах (всего 10 признаков) сравнивается с TF-IDF baseline?\n",
        "2.  Почему темы могут быть хуже или лучше как признаки в данной задаче?"
      ],
      "metadata": {
        "id": "LIwNRE0_S6k0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "yuoiSKZtS-wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бонус Word2Vec (CBOW vs Skip-gram) (до +1 балла)\n"
      ],
      "metadata": {
        "id": "-Q4XFyFCTFRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Идея:** обучим нейросетевые эмбеддинги Word2Vec двумя способами (CBOW и Skip-gram), сравним, какие слова они считают похожими, и попробуем классификацию через усреднение векторов слов."
      ],
      "metadata": {
        "id": "kUnGuJz8VFbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотека `gensim` принимает на вход список списков токенов. Давайте подготовим корпуса токенов."
      ],
      "metadata": {
        "id": "jtufNl_TVBTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем токенайзер к каждому твитту\n",
        "# Должен получиться list of lists: [['this', 'is', ...], ['another', 'tweet', ...]]\n",
        "\n",
        "tokenized_train = # your code here # (ﾉ◕ヮ◕)ﾉ*:･ﾟ✧\n",
        "tokenized_test  = # your code here (нужно для последней части)"
      ],
      "metadata": {
        "id": "nQOV8tb1U7vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы добрались наконец-то до обучения Word2Vec."
      ],
      "metadata": {
        "id": "QdMWxbATU1rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_params = dict(\n",
        "    vector_size= #... ,\n",
        "    window= #...,\n",
        "    min_count= #...,\n",
        "    workers= #...,\n",
        "    sg= #... ,          # 0 = CBOW, 1 = Skip-gram\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Обучаем CBOW\n",
        "\n",
        "print(\"Training CBOW...\")\n",
        "w2v_cbow = Word2Vec(#...)\n",
        "\n",
        "# Обучаем Skip-gram\n",
        "\n",
        "print(\"Training Skip-gram...\")\n",
        "w2v_params_sg = w2v_params.copy()\n",
        "w2v_params_sg[\"sg\"] = 1\n",
        "w2v_sg = # (ง ͠° ͟ل͜ ͡°)ง"
      ],
      "metadata": {
        "id": "F7m0WitLUwOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте еще сравним ближайших соседей. Выберите 5–7 слов, которые точно есть в корпусе (например: \"covid\", \"virus\", \"good\", \"panic\", \"lockdown\")"
      ],
      "metadata": {
        "id": "2Q3kTwDcUgAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_words = # (⊙_⊙)\n",
        "\n",
        "for w in test_words:\n",
        "    if w in w2v_cbow.wv.key_to_index and w in w2v_sg.wv.key_to_index:\n",
        "        print(f\"\\nWORD: {w}\")\n",
        "        print(\"CBOW:\", [x[0] for x in w2v_cbow.wv.most_similar(w, topn=5)])\n",
        "        print(\"SG  :\", [x[0] for x in w2v_sg.wv.most_similar(w, topn=5)])\n",
        "    else:\n",
        "        print(f\"\\nWord '{w}' not in vocabulary\")"
      ],
      "metadata": {
        "id": "5BA9krcDUb9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Где соседи выглядят более осмысленными - у CBOW или Skip-gram?\n",
        "2.  Заметили ли вы разницу в том, какие именно ассоциации ловят модели (синонимы, контекст)?\n"
      ],
      "metadata": {
        "id": "rO_wqkD1T78T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответ: # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "ckOju6C2T94U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем сделать классификацию твитов через усреднение эмбеддингов. Сделаем \"вектор твита\" как среднее арифметическое эмбеддингов всех его слов."
      ],
      "metadata": {
        "id": "CIAsHUx0Th5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def tweet_embedding(tokens, model, dim=100):\n",
        "    # 1. Создаем список векторов для слов, которые есть в модели\n",
        "    # 2. Если слов нет (пустой список), возвращаем вектор из нулей\n",
        "    # 3. Иначе возвращаем среднее (mean)\n",
        "    return\n",
        "\n",
        "# Строим матрицы\n",
        "X_train_w2v_cbow = # your code here\n",
        "X_test_w2v_cbow  = # your code here\n",
        "\n",
        "X_train_w2v_sg = # your code here\n",
        "X_test_w2v_sg  = # your code here\n",
        "\n",
        "# Оцениваем классификатор\n",
        "clf = # your code here\n",
        "\n",
        "# your code here: fit/predict для CBOW и для SG отдельно\n",
        "\n",
        "print(\"W2V-CBOW test acc:\", # ...)\n",
        "print(\"W2V-SG test acc:\", # ...)"
      ],
      "metadata": {
        "id": "sdUjAuiLTR7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Сравните качество Word2Vec-подхода с TF-IDF.\n",
        "2.  Почему простое усреднение эмбеддингов часто проигрывает TF-IDF на задаче анализа тональности?\n",
        "3.  В каких случаях эмбеддинги могли бы сработать лучше (интуитивно)?"
      ],
      "metadata": {
        "id": "duqob_-9TOQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:** # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "qqpdmXAmTtbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Заключение"
      ],
      "metadata": {
        "id": "Kb4SYrBHTuRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы попробовали 4 разных подхода к векторизации:\n",
        "\n",
        "- Bag-of-Words / CountVectorizer (просто частоты)\n",
        "\n",
        "- TF-IDF (взвешенные частоты)\n",
        "\n",
        "- LSA (снижение размерности)\n",
        "\n",
        "- Word2Vec (плотные эмбеддинги)\n",
        "\n",
        "Вопрос такой. Какой метод показал лучшее соотношение качество / сложность / время? Если бы вы делали продакшн-систему для фильтрации токсичных комментариев в реальном времени, что бы вы выбрали?\n",
        "\n",
        "#### your text here ( •̀ ω •́ )✧\n",
        "\n",
        "а еще здесь ваши общие впечатления о домашней работе 🙏🏻"
      ],
      "metadata": {
        "id": "mfuQvCRIUD8U"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}